{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eclipse2ant/math_walk/blob/master/math_walk_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. 機械学習、ディープラーニング、統計学\n"
      ],
      "metadata": {
        "id": "9-PPJfmrItBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- この講義は、どちらかというと文系の学生さん向けに書いてます。文系の学生でも、避けて通れないのがエビデンスのため統計学、また今日の状況として、ディープラーニング（深層学習）や機械学習への関りは避けて通れません。"
      ],
      "metadata": {
        "id": "qLqoTZenTOqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- その際にどうしても必要なのが微積分の知識それも多変数の場合の話で偏微分や重積分が必要で、統計学では重回帰や因子分析などの多変量解析、またロジステック回帰などの一般化線形モデル、またベイズ統計の知識、あるいは時系列解析などの知識が今後ますます必要になってきます。今日、自然言語処理、BERTなどでは次元削減、行列を使うので線形代数の知が。また画像処理、さらには自動運転（例えば　雑誌Interface の2023年4月号）はディーラーニングの特集　自動運転のデータ作りでJetson TensorRT、あるいはTransformer　とかが特有記事です。[雑誌　interface 2023年4月号](https://shop.cqpub.co.jp/hanbai/books/MIF/MIF202304.html)。"
      ],
      "metadata": {
        "id": "LlVhkIXBTFmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 経済ではNFTなどの仮想通貨やブロックチェーンがらみの話、フィンテックというITやAIをふんだんに使った市場経済。教育も今後大きく変わってくるでしょう（ていうか既にに変わってきてるけど、頭の固いに日本人は遅れてるのかも。教育のDX）。"
      ],
      "metadata": {
        "id": "teQYsJTbTg1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ここでは、微積分の多変数の場合、重積分も含めて、概念的なことをイメージ的につかんでもらおうと思います。細かい計算は、おそらく、コンピューターがやってくれるでしょう。"
      ],
      "metadata": {
        "id": "lJ7-c5dUTx0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 例えば統計ソフトのR や　Pythonを使ったデータサイエンス、基本はmatlibplot, numpy, Pandas その他の統計計算ライブラリーやTensorflowなどなど、あと、Pythonの代わりにJuliaを使う場合もあるでしょう。つまり概念や原理を知っておく必要はあるけど計算はこれらのソフトをつかう、要はそのソフトのやってるkとがわからないとその出力結果がわからない。だから微積といっても普通の微積をやっても役に立たない。ビッグデータだと100万とか100億個の変数が出てくるらしいです。そこで計算機に出てくることで何を見るかは普通の微積分の話とは違いますよね。でも概念は大切です。そのつもりで学んでください。"
      ],
      "metadata": {
        "id": "7lqsjudJT9LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11.1.  1変数の微分について\n",
        "- まず $f: {\\mathbb R}  \\longrightarrow {\\mathbb R}$ が微分可能であるとき、$x_0$での微分について考えてみよう。微分とは、$(x_0,f(x_0))$ で接線を引くことです。この傾きが微分係数です。[Tangent_space.pdf](https://drive.google.com/file/d/15bcF8ZjQUkrg-xmNmy8GurYdYNUjkAxc/view?usp=share_link) の(a) を見てください。その接線とは、$(x_0,f(x_0))$ を原点とすると、原点を通る1次関数$y=ax$　つまり比例で近似しているわけです。比例または1次関数$y=ax$ を線形写像といいます。微分とは線形写像で近似することです。これを(b)のように描き直してみましょう。(b)におけるピンクの線は、$x_0, f(x_0)$ のそれぞれの点で${\\mathbb R}$を新たに設けてそこで(a)においての1次関数（つまり線形写像）を描いてます。このピンクの線はそれぞれの点における ${\\mathbb R}$ の **接空間** といい、それぞれ $T_{x_0}({\\mathbb R}),\\  T_{f(x_0)}({\\mathbb R})$ と表します。"
      ],
      "metadata": {
        "id": "QWaXsNTUUA4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2. 多変数の微分について、チェイン・ルール、逆関数定理、陰関数定理"
      ],
      "metadata": {
        "id": "JqwOdfk475JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 次に、$f: {\\mathbb R}^2  \\longrightarrow {\\mathbb R}^2$  のときを考えてみましょう。(c) でのピンクの線は、それぞれ ${\\mathbb R}^2$ になります。 ${\\mathbb R}^2$  の $x_0$ での接空間ですからね。ピンクの線は、$x_0, f(x_0)$ のそれぞれの点での **ファイバー(fiber)** といいます。$f$ の点 $x_0$ での微分とは、$x_0$ 上のファイバー $T_{x_0}({\\mathbb R}^2)$ から $f(x_0)$ 上のファイバー $T_{f(x_0)}({\\mathbb R}^2)$ への２次元バージョンの比例で行列$A$で書けて、やはり $y=Ax$ ここで、$x,y$はベクトルで、これも線形写像になっています。線形とは多次元版比例のことです、この$A$を$f$  の**ヤコビ行列** といいます。"
      ],
      "metadata": {
        "id": "Gpri9wh4kIr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ここでの注意は $A$ で局所的に 点$x_0$ の近くで　$f$ を線形つまり多次元版比例で近似したわけです。この近似側で逆写像が存在すると元の $f$ の方も $x_0$ の近くで逆写像が存在します。これが逆関数定理で同様な感じで陰関数定理もあります。またもとでの合成関数とると近似も合成関数になります。これがチェイン・ルールです。"
      ],
      "metadata": {
        "id": "P8PeNa8zqjDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.3. 球面ないしは曲面（多様体）から　球面への微分"
      ],
      "metadata": {
        "id": "VnzIt3KT8cI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 次に球面から球面へ場合を考えてみましょう。(d)にあるように、接空間 $T_{x_0}(S^2)$ は、$S^2$ 上の点 $x_0$ で接する接平面であり、$x_0$ を通る直線 $c$ の $x_0$ での接ベクトルで張られます。この接ベクトル $\\frac{dc}{dt}(0)$ に対して、$\\frac{d(f \\circ c)}{dt}(0)$ を対応させる写像が $T_{x_0}(S^2)$ から $T_{f(x_0)}(S^2)$ への線形写像となり、$(df)_{x_0}$ となります。ここで接ベクトルを表す曲線に自由度がありますが、この自由度に子の写像は依存しないことに注意してください"
      ],
      "metadata": {
        "id": "YC4J5MBpls0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ここで、初めて、平面のような平らな世界ではなく歪んだ世界を考えました。曲面などの歪んだ世界を扱う場合 [以下の図](https://drive.google.com/file/d/1P77H8kz62Tzp_cVF6RLzesVLQtJpkd41/view?usp=share_link) のように$U_1, U_2$ のように部分的に$\\phi_1, \\phi_2$ で表されます(図ではこれは複素多様体の場合をやってるので $C$ ですがここでは $R$ だと思ってください。また、(d) の場合に、実際、点 $x_0,f(x_0)$ の局所座標をとってこの座標を見てあげると、(c)の場合に帰着します。"
      ],
      "metadata": {
        "id": "MqOZq0Jel8qV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.4. 積分について"
      ],
      "metadata": {
        "id": "uLYGOxb285hP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- まず1変数の場合に、よく初等的な微積分の本や講義では、積分を微分の逆演算として定義してますが、本来、積分は面積や体積を求めるために考え出されたもので、無限和が定義です。しかしこのリーマン積分の定義は説明が面倒で、特に閉区間で連続関数にしか適用できません。しかも連続性から閉区間がコンパクトなことから一様連続であることをつかって和の収束性を示すもので、分割の仕方で、帰納的極限などの説明が必要で面倒だからです。不定積分が微分の逆演算になるのは定理です。積分が極限操作などとうまく整合性をとるには関数が連続よりももっと一般の場合に積分の定義をする必要があってそこでルベーグ積分が出てきます。ルベーグ測度という測度論の話がここでは必要になりますが、確率論の話でない限り、統計学の方ではあまり測度論は出てきません、本来、統計の確率変数は、可測関数で測度空間上で定義されるものです。"
      ],
      "metadata": {
        "id": "QDS-jvmC8-62"
      }
    }
  ]
}